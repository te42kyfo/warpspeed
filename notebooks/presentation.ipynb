{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../applications/')\n",
    "sys.path.append('../measutils/')\n",
    "sys.path.append('../warpspeed/')\n",
    "\n",
    "\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as drv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import measure_metric.measureMetric as measureMetric\n",
    "\n",
    "from stencilgen.stencil import *\n",
    "from tsmgen.kernel import *\n",
    "import stencilgen.bench as stencilbench\n",
    "import tsmgen.benchmark as tsmbench\n",
    "from predict import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport stencilgen.stencil\n",
    "%aimport stencilgen.bench\n",
    "%aimport predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "\n",
    "                                         launch config\n",
    "                                           |\n",
    "                                           v             \n",
    "    Generator -> Perf Characteristics -> Prediction  \n",
    "        |\n",
    "        v\n",
    "      Code\n",
    "  \n",
    "  \n",
    "- Predict performance from a few code characteristics that any code generator can generate alongside the code\n",
    "- No look at the actual code, no attempt to derive data from code\n",
    "- Limitation to kernels:\n",
    "    - no (complex) control flow\n",
    "    - no indirect accesses\n",
    "- Perf characteristics:\n",
    "    - load/stores with expression for the address dependent only on thread ID\n",
    "    - number of FP operations\n",
    "    - (dependence of FP ops)\n",
    "    - (# of Int operations)\n",
    "- Launch config: \n",
    "    - block size\n",
    "    - grid size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exmaples for Generators: stencils and TSMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel =  Kernel2DBoxStencil(stencil_range = 1, l1only=True, singleTid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( kernel.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stencilbench.printSASS(kernel.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsmkernel = Kernel(64, 64, 2, 2, 128, dtype=\"double\", transposed=True, leapFrog=False)\n",
    "print(tsmkernel.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsmbench.printSASS(tsmkernel.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase Model\n",
    "\n",
    " - Compiled kernels usually have a typical structure with distinct phases:\n",
    "  \n",
    "       INT\n",
    "       LD \n",
    "       FP \n",
    "       ST (optional)\n",
    "       jb/exit \n",
    "   \n",
    " - INT ususally contains address calculations\n",
    " - All LD instructions are moved to the front of the loop/program for maximum overlap of memory latencies\n",
    " - Phases may overlap by some amount for larger kernels, to save on registers  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution phases\n",
    "\n",
    "    -                      -\n",
    "    | (Tint)               |\n",
    "    -      –               |\n",
    "    |      |               |\n",
    "    | Tld  |               |\n",
    "    |      |               |\n",
    "    –      | Tlat          |\n",
    "           |               |\n",
    "           |               |\n",
    "           |               | Ttotal\n",
    "       -   -  –            |\n",
    "       |      |            |\n",
    "       |      |            |\n",
    "       | Tfp  | Tl1_thru   |\n",
    "       |      |            |\n",
    "       |      -            |\n",
    "       –                   -\n",
    "       \n",
    " - INT execution is difficult for the generator to generate, and difficult to predict, because various rates/latencies and usually some overlap with LD phase. Necessary for precise L1 bound predictions though. Small impact for memory bound cases, so usually omitted\n",
    " \n",
    " - LD execution phase: time taken to just enqueue the loads. Executed at a constant 1/4cyc throughput, regardless of cache hit/miss. Similar to INT execution: sometimes coissued with FP, overlaps with memory latency. Necessary for precise L1 bound predictions, where latency is short. Can be omitted otherwise\n",
    "\n",
    " - Tlat = Tlat_mem + Tlat_L2 = (271 + 200) cyc\n",
    "\n",
    " - FP (DP) execution phase: 1/4 throughput, 8cyc latency. \n",
    " - L1 thru: Four 32B L1 cache lines per cycle\n",
    "\n",
    " - Assumption: the very first load instruction is a cache miss and loads from memory. All other cache misses hide behind that latency and are considered L1 cache hits. Tlatency therefore overlaps with Tld.\n",
    " \n",
    " - The FP phase can start as soon as the first load has returned, after Tlat. The L1 cache can now also start the outstanding load delievery phase Tl1_thru, depending on L1 bandwidth. Overlaps with DP phase (not quite perfectly sometimes)\n",
    "\n",
    "\n",
    " - Single warp execution time: Ttotal = Tint + max(Tld, Tlat) + max(Tfp, Tl1_thru) \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiwarp execution time\n",
    "\n",
    "\n",
    "- GPUs do not execute single warps (duh)\n",
    "- Performance: \"P = Nflop * Nwarps * clock / Ttotal\" is too simple, does not scale with increased warp count\n",
    "- warps compete for ressources:\n",
    "  - L2 and memory bandwidth is shared by all 80 SMs.\n",
    "  - L1 bandwidth is shared by the four quadrants of a SM\n",
    "  - execution units are are shared by the (up to 16) warps per quadrant\n",
    "  - In CPU terms: SMT16\n",
    "\n",
    "- Phase execution time increases, e.g.\n",
    "  - Tdp = Ndp * 8 * min(1, Nquad / 2)\n",
    "  - Tl1_thru = Nsm * Ncl_L1 / 4\n",
    "\n",
    "- This model is also too simple! would correspond to perfectly synchronized phase execution: at every point all warps execute the same phase -> minimum overlap of phases\n",
    "\n",
    "- Most optimistic model: perfect desynchronization -> maximum overlap. In practice probably not quite perfect desynchronization, but more realistic than synchronicity\n",
    "\n",
    "- Perfect desync overlap model e.g.:\n",
    "  - Tdp = Ndp * 8 * min(1,Nquad * Tdp / Ttotal / 2)\n",
    "  - Tl1_thru = Nsm * Tl1_thru / Ttotal / 4\n",
    "\n",
    "- Equation for Ttotal now contains Ttotal...\n",
    " -> solve iteratively\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: 2D Box Stencil with varying range\n",
    "- Try all block sizes, plot the best block size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_values = []\n",
    "for r in range(1, 7):\n",
    "    values = []\n",
    "    kernel = Kernel2DBoxStencil(stencil_range=r, l1only=True)\n",
    "    for xblock in [16, 32, 64, 128, 256, 512, 1024]:\n",
    "        for yblock in [1, 2, 4, 8, 16, 32, 64, 128]:\n",
    "            if xblock*yblock > 1024 or xblock*yblock < 64:\n",
    "                continue\n",
    "\n",
    "            stencilbench.A_gpu_aligned = int(stencilbench.A_gpu)\n",
    "            stencilbench.B_gpu_aligned = int(stencilbench.B_gpu)\n",
    "            values.append(stencilbench.benchKernel(kernel, 11, (xblock, yblock, 1))[2])\n",
    "            \n",
    "    best_values.append(np.max(np.array(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "\n",
    "plt.axhline(np.max(np.array(best_values)))\n",
    "\n",
    "plt.bar(np.arange(1, len(best_values)+1), best_values, width=0.7)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Volume\n",
    "\n",
    "- How to get the number of loaded L1 cache lines?\n",
    "- The number of L2 cache lines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kernel2DBoxStencil(stencil_range=1).genAddresses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storeVolumes = []\n",
    "loadVolumes = []\n",
    "for r in range(1, 10):\n",
    "    kernel = Kernel2DBoxStencil(stencil_range=r, l1only=True)\n",
    "    \n",
    "    measureMetric.measureBandwidthStart()\n",
    "    block = (32, 8, 1)\n",
    "    stencilbench.runKernel(kernel, kernel.getGrid(1, block, 15000, 15000), block)\n",
    "    result = measureMetric.measureMetricStop()\n",
    "    \n",
    "    storeVolumes.append(result[1])\n",
    "    loadVolumes.append(result[0])\n",
    "    print(\"mem load: \" + str(result[0] / 15000**2))\n",
    "    print(\"mem store: \" + str(result[1] / 15000**2))\n",
    "    print(\"L2  load: \" + str(result[2]*32 / 15000**2))\n",
    "    print(\"L2  store: \" + str(result[3]*32 / 15000**2))\n",
    "    L2CLs, L1CLs = computeCacheVolumes(kernel, 32, block, (1,1,1))\n",
    "    \n",
    "    print(\"pred L1 CLs: \" + str(L1CLs))\n",
    "    print(\"pred L2 volume: \" + str(L2CLs * 32 / block[0] / block[1] / block[2]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_values = []\n",
    "\n",
    "measuredValues = []\n",
    "predictedValues = []\n",
    "\n",
    "for r in range(1, 5):\n",
    "    kernel = Kernel2DBoxStencil(stencil_range=r, l1only=True)\n",
    "    for xblock in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "        for yblock in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "            if xblock*yblock > 1024 or xblock*yblock < 32:\n",
    "                continue\n",
    "\n",
    "            block = (xblock, yblock, 1)\n",
    "                        \n",
    "            print(r, end=\" \")\n",
    "            print(block, end=\" \")\n",
    "            print(block[0] * block[1] * block[2], end=\"\\n\")\n",
    "            stencilbench.A_gpu_aligned = int(stencilbench.A_gpu)\n",
    "            stencilbench.B_gpu_aligned = int(stencilbench.B_gpu)\n",
    "            measuredValues.append( stencilbench.benchKernel(kernel, 11, (xblock, yblock, 1))[2])\n",
    "            predictedValues.append(predictPerformance(kernel, block, (1,1,1), 32) )\n",
    "\n",
    "            print(\"{:.0f}  {:.0f}\".format( measuredValues[-1], predictedValues[-1]))\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "\n",
    "ax.plot(measuredValues, \"-x\", label=\"measured\")\n",
    "ax.plot(predictedValues, \"-+\", label=\"predicted\")\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busyFactor(p):\n",
    "    return max(1, p)\n",
    "    #return 1 + (log( 1 + exp((p-1)  )))\n",
    "\n",
    "def predictPerformance(kernel, block, grid, registers):\n",
    "\n",
    "    threadsPerBlock = block[0]*block[1]*block[2]\n",
    "    blocksPerSM = min( 32, int(2**16 / (threadsPerBlock * max(registers, 32)) ))\n",
    "    warpsPerSM = blocksPerSM * ((threadsPerBlock-1) // 32 + 1)\n",
    "    warpsPerBlock = ceil(threadsPerBlock / 32)\n",
    "    \n",
    "    SMcount = 80 \n",
    "    clock = 1.38    \n",
    "    cl_size = 32\n",
    "    blockShedRate = 0.46\n",
    "    L2CLs, L1CLs = computeCacheVolumes(kernel, cl_size, block, grid)\n",
    "\n",
    "    L2CLs += threadsPerBlock / 4\n",
    "    L1LoadCycles = sum([ len(ld) for ld in L1CLs ]) / 4   / warpsPerBlock\n",
    "    print(L1LoadCycles)\n",
    "\n",
    "    # Iitial values\n",
    "    #Tint = 40 * 5 * max(1, warpsPerSM / 12)\n",
    "    Tint = 0\n",
    "    TL1thru = (L1LoadCycles * blocksPerSM) \n",
    "    TDP  = kernel.flops * max(1, (warpsPerSM / 8))  * 8\n",
    "    Tlat_mem = (max(250,  (warpsPerSM*32*16 * SMcount ) / 780 * clock ) if kernel.bytes > 0 else 0)\n",
    "    Tlat_L2 = (max(200,  (L2CLs * blocksPerSM * SMcount * cl_size ) / 2000 * clock ) if kernel.bytes > 0 else 0)\n",
    "    Tblocksched = SMcount / 0.5  * blocksPerSM  \n",
    "    Ttotal = Tblocksched + Tint + max(TDP, TL1thru) + Tlat_mem + Tlat_L2\n",
    "    print(\"Tblocksched Tint TL1thru TDP Tlat_mem, Tlat_L2, Ttotal\")\n",
    "    print(\"{:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f}\".format(Tblocksched, Tint, TL1thru, TDP, Tlat_mem, Tlat_L2, Ttotal ))\n",
    "    \n",
    "    delta = 100\n",
    "    for i in range(0, 200):\n",
    "        Tint = 0 #40 * 5 * busyFactor(Tint / Ttotal * warpsPerSM / 12)\n",
    "        TL1thru = L1LoadCycles  * busyFactor(TL1thru / Ttotal * warpsPerSM)\n",
    "        TDP  = kernel.flops * busyFactor(warpsPerSM * (TDP / Ttotal) / 8)  * 8 \n",
    "        Tlat_mem = max(271, Tlat_mem / Ttotal  * (warpsPerSM*32*16 * SMcount ) / 780 * clock) if kernel.bytes > 0 else 0 \n",
    "        Tlat_L2 = (max(200,  Tlat_L2 / Ttotal  * (L2CLs * blocksPerSM * SMcount * cl_size ) / 2000 * clock ) if kernel.bytes > 0 else 0)\n",
    "        new_Ttotal = Tblocksched + Tint + max(TDP,  TL1thru) + Tlat_mem + Tlat_L2\n",
    "        delta = abs(new_Ttotal - Ttotal)\n",
    "        Ttotal = new_Ttotal\n",
    "        \n",
    "        if i > 100 and delta < 0.01:\n",
    "            break\n",
    "    \n",
    "    print(\"{:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f} {:5.0f}\".format(Tblocksched, Tint, TL1thru, TDP, Tlat_mem, Tlat_L2, Ttotal ))\n",
    "    return kernel.flops * blocksPerSM * threadsPerBlock * (clock * SMcount / Ttotal )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$T_{L1thru} = C_{L1loads}  F_{busy}( \\frac{T_{L1thru}N_{warps} }{ T_{total}})$$\n",
    "$$T_{DP} = 8I_{Flops}  F_{busy}( \\frac{T_{DP}N_{warps} }{ 8\\quad T_{total}})$$\n",
    "$$T_{lat}^{mem} = \\max(271,  \\frac{T_{lat}^{mem}}{T_{total}} DV_{mem} / 780 * clock) $$\n",
    "$$T_{lat}^{L2} = \\max(200,  \\frac{T_{lat}^{L2}}{T_{total}} * DV_{L2} / 2000 * clock) $$\n",
    "\n",
    "$$T_{total} = T{blocksched} + T_{int} + max(T_{DP}, T_{L1thru}) + T_{lat}^{mem} + T_{lat}^{L2}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_values = []\n",
    "\n",
    "measuredValues = []\n",
    "predictedValues = []\n",
    "\n",
    "for r in range(1, 5):\n",
    "    kernel = Kernel2DBoxStencil(stencil_range=r)\n",
    "    \n",
    "    for xblock in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "        for yblock in [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "            if xblock*yblock > 1024 or xblock*yblock < 32:\n",
    "                continue\n",
    "\n",
    "            block = (xblock, yblock, 1)\n",
    "                        \n",
    "            print(r, end=\" \")\n",
    "            print(block, end=\" \")\n",
    "            print(block[0] * block[1] * block[2], end=\"\\n\")\n",
    "            stencilbench.A_gpu_aligned = int(stencilbench.A_gpu)\n",
    "            stencilbench.B_gpu_aligned = int(stencilbench.B_gpu)\n",
    "            measuredValues.append( stencilbench.benchKernel(kernel, 11, (xblock, yblock, 1))[2])\n",
    "            predictedValues.append(predictPerformance(kernel, block, (1,1,1), 32) )\n",
    "\n",
    "            print(\"{:.0f}  {:.0f}\".format( measuredValues[-1], predictedValues[-1]))\n",
    "            print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(16)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "\n",
    "ax.plot(measuredValues, \"-x\", label=\"measured\")\n",
    "ax.plot(predictedValues, \"-+\", label=\"predicted\")\n",
    "#ax.set_yscale(\"log\")\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Kernel2DBoxStencil(stencil_range=r).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
